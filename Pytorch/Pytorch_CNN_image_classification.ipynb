{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95e8ad2-2581-4297-850b-5d0bb43d2b48",
   "metadata": {},
   "source": [
    "# Pytorch CNN image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573e7e1e-5602-4023-b098-b3d2722f3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59192001-74ce-4a32-9739-0408808064d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916895fb-36f9-4460-9984-c49dfe49312e",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0beeecf6-4e1b-4d5d-a9ed-96f96b4c9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/glade/u/home/ksha/torch_data/'\n",
    "batch_size = 64\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a83a5a2-7de4-4a4a-b3b3-dadaed3da26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root=path_data, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=path_data, train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93f2cab-7011-4496-813c-7e6dae42fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(trainloader)\n",
    "# images, labels = next(dataiter)\n",
    "# imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff38d75-8e17-4b85-84b7-4136f91774b4",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a92f9a-8c0a-4a99-b5df-7cbed2155228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "class model_maker(nn.Module):\n",
    "    def __init__(self, input_num, class_nums):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.filter_nums = [64, 128, 256]\n",
    "        self.dense_nums = [256, 64]\n",
    "        \n",
    "        self.conv2d_layer0 = nn.Conv2d(input_num, self.filter_nums[0], kernel_size=3, padding='same')\n",
    "        self.conv2d_layer1 = nn.Conv2d(self.filter_nums[0], self.filter_nums[1], kernel_size=3, padding='same')\n",
    "        self.conv2d_layer2 = nn.Conv2d(self.filter_nums[1], self.filter_nums[2], kernel_size=3, padding='same')\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.dense_layer0 = nn.LazyLinear(self.dense_nums[0])\n",
    "        self.dense_layer1 = nn.LazyLinear(self.dense_nums[1])\n",
    "        \n",
    "        self.dense_out = nn.LazyLinear(class_nums)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv2d_layer0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2d_layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2d_layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.dense_layer0(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dense_layer1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dense_out(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = model_maker(input_num=3, class_nums=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53871b69-2e40-464d-9255-1dea4566e664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_maker(\n",
       "  (conv2d_layer0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (conv2d_layer1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (conv2d_layer2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dense_layer0): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (dense_layer1): LazyLinear(in_features=0, out_features=64, bias=True)\n",
       "  (dense_out): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e224a-a190-4dc5-a92e-7cf59b8d06ee",
   "metadata": {},
   "source": [
    "**Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b09239-5a1a-4967-8e04-0ac53c6676a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb6bed1-83fc-492e-8053-ed7c61a6498b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae42c3b9-9c2d-4ae0-9a16-19c5f0adbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/glade/work/ksha/torch_models/cifar_net.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb05932-f63f-4544-a47e-8bf42fff7f51",
   "metadata": {},
   "source": [
    "**Validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0e568fa-45ab-4f74-a1cb-148ce341060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_valid = len(testset)\n",
    "input_, y_true_ = testset[0]\n",
    "\n",
    "grid_shape = np.array(input_).shape\n",
    "input_test = np.empty((L_valid,)+grid_shape)\n",
    "y_true = np.empty(L_valid)\n",
    "\n",
    "for i in range(L_valid):\n",
    "    input_, y_true_ = testset[i]\n",
    "    input_test[i, ...] = np.array(input_)\n",
    "    y_true[i] = y_true_\n",
    "\n",
    "y_true = torch.from_numpy(y_true).long()\n",
    "input_test = torch.from_numpy(input_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8c448c5-9959-436a-9013-737ada465ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.3033981323242188\n",
      "Validation loss: 2.247927188873291\n",
      "Validation loss improved from 2.3033981323242188 to 2.247927188873291\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.853750228881836\n",
      "Validation loss improved from 2.247927188873291 to 1.853750228881836\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.6193350553512573\n",
      "Validation loss improved from 1.853750228881836 to 1.6193350553512573\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.488877773284912\n",
      "Validation loss improved from 1.6193350553512573 to 1.488877773284912\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.3921916484832764\n",
      "Validation loss improved from 1.488877773284912 to 1.3921916484832764\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.3202134370803833\n",
      "Validation loss improved from 1.3921916484832764 to 1.3202134370803833\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.2563410997390747\n",
      "Validation loss improved from 1.3202134370803833 to 1.2563410997390747\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.2223827838897705\n",
      "Validation loss improved from 1.2563410997390747 to 1.2223827838897705\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.1182270050048828\n",
      "Validation loss improved from 1.2223827838897705 to 1.1182270050048828\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n",
      "Validation loss: 1.0624972581863403\n",
      "Validation loss improved from 1.1182270050048828 to 1.0624972581863403\n",
      "Save to /glade/work/ksha/torch_models/cifar_net.pth\n"
     ]
    }
   ],
   "source": [
    "min_del = 0.0\n",
    "max_tol = 3 # early stopping with 2-epoch patience\n",
    "tol = 0\n",
    "\n",
    "y_pred = model(input_test)\n",
    "record = loss_func(y_pred, y_true).detach().numpy()\n",
    "print('Initial loss: {}'.format(record))\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # on-epoch-end validation\n",
    "    y_pred = model(input_test)\n",
    "    record_temp = loss_func(y_pred, y_true).detach().numpy()\n",
    "    print('Validation loss: {}'.format(record_temp))\n",
    "    \n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        print(\"Save to {}\".format(save_dir))\n",
    "        torch.save(model.state_dict(), save_dir)\n",
    "        \n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121127fb-5459-4243-8576-c200af3338b4",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a02f6eb-9697-42b7-879e-5867e0ecd53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_maker()\n",
    "model.load_state_dict(torch.load(save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5adf9e7-2842-4bbb-bbc4-04f54b03b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59566d78-a153-41bb-9e98-9e35d85fe209",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdfc0a51-7968-46a4-ba95-c694d6df5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/glade/work/ksha/torch_models/cifar_net_tune.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0124b35-2f15-49bf-a2d2-92740d63b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_del = 0.0\n",
    "max_tol = 3 # early stopping with 2-epoch patience\n",
    "tol = 0\n",
    "\n",
    "y_pred = model(input_test)\n",
    "record = loss_func(y_pred, y_true).detach().numpy()\n",
    "print('Initial loss: {}'.format(record))\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # on-epoch-end validation\n",
    "    y_pred = model(input_test)\n",
    "    record_temp = loss_func(y_pred, y_true).detach().numpy()\n",
    "    print('Validation loss: {}'.format(record_temp))\n",
    "    \n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        print(\"Save to {}\".format(save_dir))\n",
    "        torch.save(model.state_dict(), save_dir)\n",
    "        \n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2533d-ed69-46c4-b228-fa9a11cb3292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
